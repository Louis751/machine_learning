{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于sklearn的文本特征抽取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理论"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习的样本一般都是特征向量，但是除了特征向量以外经常有非特征化的数据，最常见的就是文本"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结构化数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当某个特征为有限的几个字符串时，可以看成一种结构化数据，处理这种特征的方法一般是将其转为独热码的几个特征。例如仅能取三个字符串的特征：a,b,c，可以将其转换为001,010,100的三个特征和"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 非结构化数据\n",
    "当特征仅是一系列字符串时，可以使用词袋法处理，这种方法不考虑词汇顺序，仅考虑出现的频率\n",
    "\n",
    "count vectorizer：仅考虑每种词汇出现的频率\n",
    "tfidf vectorizer：除了考虑词汇出现的频率，还考虑词汇在样本总体中出现频率的倒数，可以理解为抑制每个样本中都经常出现的词汇\n",
    "\n",
    "对于经常出现的无意义词汇，如the和a等，可以将其指定为停用词消除其对于结果的干扰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14134 4712\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(news.data,news.target,test_size=0.25,random_state=33)\n",
    "print(len(x_train),len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vec = CountVectorizer()\n",
    "x_count_train = c_vec.fit_transform(x_train)\n",
    "x_count_test = c_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count vectorizer+去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_vec_s = CountVectorizer(analyzer='word',stop_words='english')\n",
    "x_count_stop_train = c_vec_s.fit_transform(x_train)\n",
    "x_count_stop_test = c_vec_s.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vec = TfidfVectorizer()\n",
    "x_tfidf_train = t_vec.fit_transform(x_train)\n",
    "x_tfidf_test = t_vec.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf vectorizer+去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_vec_s = TfidfVectorizer(analyzer='word',stop_words='english')\n",
    "x_tfidf_stop_train = t_vec_s.fit_transform(x_train)\n",
    "x_tfidf_stop_test = t_vec_s.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8397707979626485"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_c = MultinomialNB()\n",
    "nb_c.fit(x_count_train,y_train)\n",
    "nb_c.score(x_count_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### count vectorizer+去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8637521222410866"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_cs = MultinomialNB()\n",
    "nb_cs.fit(x_count_stop_train,y_train)\n",
    "nb_cs.score(x_count_stop_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8463497453310697"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_t = MultinomialNB()\n",
    "nb_t.fit(x_tfidf_train,y_train)\n",
    "nb_t.score(x_tfidf_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tfidf vectorizer+去除停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8826400679117148"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_ts = MultinomialNB()\n",
    "nb_ts.fit(x_tfidf_stop_train,y_train)\n",
    "nb_ts.score(x_tfidf_stop_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
